{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7faa5-8bf9-4e63-a601-09bbb10b688e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating speech for segment 1 by speaker A\n",
      "Generating speech for segment 1 by speaker B\n",
      "Generating speech for segment 2 by speaker A\n",
      "Generating speech for segment 2 by speaker B\n",
      "Generating speech for segment 3 by speaker A\n",
      "Generating speech for segment 3 by speaker B\n",
      "Generating speech for segment 4 by speaker A\n",
      "Generating speech for segment 4 by speaker B\n",
      "Generating speech for segment 5 by speaker A\n",
      "Generating speech for segment 5 by speaker B\n",
      "Generating speech for segment 6 by speaker A\n",
      "Generating speech for segment 6 by speaker B\n",
      "Generating speech for segment 7 by speaker A\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import io\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"config.env\")\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "content = [\n",
    "    {\n",
    "        \"A\": \"Hello, dear listeners, and welcome to this episode of the Technology Interview program. Today, we have invited Mr. Yucheng, the Head of Technology at SynthMind AI, to discuss the hot topic of AI Agents with us. Hello, Yucheng!\",\n",
    "        \"B\": \"Hello, host, and hello to all the listeners! I'm delighted to be here to discuss AI Agents with everyone.\"\n",
    "    },\n",
    "    {\n",
    "        \"A\": \"AI Agents have been making waves lately, and many believe they are a crucial step towards achieving general artificial intelligence. Yucheng, could you please briefly introduce what exactly an AI Agent is?\",\n",
    "        \"B\": \"Sure. An AI Agent is an artificial intelligence entity capable of perceiving its environment, making decisions, and taking actions like humans. They can be software programs or embodied robots. Unlike traditional AI systems, AI Agents are more autonomous and flexible, capable of operating independently in complex and dynamic environments.\"\n",
    "    },\n",
    "    {\n",
    "        \"A\": \"That sounds impressive! What are the specific characteristics of AI Agents?\",\n",
    "        \"B\": \"AI Agents mainly have four characteristics: Autonomy: AI Agents can operate independently without human intervention, making decisions, and taking actions autonomously. For example, Auto-GPT requires you to set a goal, and it will independently plan and execute actions to achieve that goal. Reactivity: AI Agents can perceive changes in their surroundings and respond to them. For instance, in games, AI Agents can adjust their strategies based on opponents' actions. Proactivity: AI Agents can not only respond to the environment passively but also take proactive actions to change the environment. For example, a learning AI Agent will actively search for learning materials to enhance its skills. Social Ability: AI Agents can communicate and collaborate with other AI Agents or humans. For instance, in software development, multiple AI Agents can communicate in natural language to complete tasks together.\"\n",
    "    },\n",
    "    {\n",
    "        \"A\": \"Wow, AI Agents are quite capable! What are their current application scenarios?\",\n",
    "        \"B\": \"AI Agents have a wide range of applications, such as: Rule-based Agents: These are relatively simple AI Agents whose decisions and actions follow predefined rules. They can be used in scenarios like traffic light control and automated production lines. Reactive Agents: These AI Agents react directly to environmental stimuli without complex planning or reasoning. They can be used in scenarios like robot navigation and game AI. Goal-oriented Agents: These AI Agents have clear objectives and use planning and decision algorithms to achieve these goals. They can be used in scenarios like chess games and path planning. Learning Agents: These AI Agents can learn from experience and improve their performance over time, such as in recommendation systems and personalized education.\"\n",
    "    },\n",
    "    {\n",
    "        \"A\": \"It sounds like the internal mechanisms of AI Agents are quite complex! How do they actually work?\",\n",
    "        \"B\": \"The working principle of an AI Agent can be likened to the human brain. It usually consists of several core modules: 'Brain' Module: This is the core of the AI Agent, responsible for high-level cognition and decision-making, such as understanding human instructions, planning, reasoning, etc. Large Language Models (LLMs) are typically the core component of this module, providing strong language understanding and generation capabilities. 'Perception' Module: This module receives and processes information from the external environment, such as text, images, sound, etc. It's like the eyes, ears, and nose of the AI Agent, helping it understand its surroundings. 'Action' Module: This module executes decisions, such as controlling robot movements, generating text, using tools, etc. It's like the hands and feet of the AI Agent, enabling it to perform tasks in the real or virtual world. 'Memory' Module: This module stores the AI Agent's experiences and knowledge, which the 'Brain' module references during reasoning and planning. It's like the memory repository of the AI Agent's brain, helping it learn from past experiences and make better decisions in the future. 'Planning' Module: This module formulates specific steps to achieve goals and breaks down high-level plans into executable action sequences. It's like the planner for the AI Agent, helping it complete tasks efficiently. These modules collaborate to allow the AI Agent to process information, make decisions, and take actions like humans.\"\n",
    "    },\n",
    "    {\n",
    "        \"A\": \"Wow, that's amazing! It seems AI Agents have great potential for future development! What do you think are the future trends for AI Agents?\",\n",
    "        \"B\": \"I think the future development trends for AI Agents are mainly in the following areas: LLM-Based Agents: In the future, more AI Agents will use large language models (LLMs) as their core components, giving them stronger language understanding and generation capabilities, allowing for more natural and fluent interactions with humans. Multi-modal Agents: Future AI Agents will be able to handle multiple modalities of information, such as images, sound, video, etc., enabling a more comprehensive perception of the world and completion of more complex tasks. Embodied Agents: Combining the intelligence of AI Agents with the physical world, allowing them to perform tasks in real environments, such as controlling robots for navigation or object manipulation in the real world, will be an important development direction. Agent Society: Exploring interactions and social phenomena among AI Agents and researching how to build smarter and more collaborative AI systems are also important directions for future development.\"\n",
    "    },\n",
    "    {\n",
    "        \"A\": \"Thank you very much for your wonderful insights, Yucheng! I believe that as AI technology continues to evolve, AI Agents will play an increasingly important role in the future, bringing more convenience and surprises to our lives.\",\n",
    "        \"B\": \"Thank you, host! And thank you to all the listeners for tuning in!\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def split_text(text, max_length=4096):\n",
    "    \"\"\"Split the text into multiple chunks, with each chunk not exceeding the specified maximum length.\"\"\"\n",
    "    return [text[i:i + max_length] for i in range(0, len(text), max_length)]\n",
    "\n",
    "def generate_speech_chunk(client, model, input_text, voice, response_format='mp3', speed=1.0):\n",
    "    \"\"\"Generate speech for a single text chunk using OpenAI's TTS API.\"\"\"\n",
    "    response = client.audio.speech.create(\n",
    "        model=model,\n",
    "        voice=voice,\n",
    "        input=input_text,\n",
    "        response_format=response_format,\n",
    "        speed=speed\n",
    "    )\n",
    "\n",
    "    return response.content\n",
    "\n",
    "def merge_audio_files(audio_files, output_path):\n",
    "    \"\"\"Merge multiple audio files into a single complete audio file.\"\"\"\n",
    "    combined_audio = AudioSegment.empty()\n",
    "    \n",
    "    for audio_content in audio_files:\n",
    "        segment = AudioSegment.from_file(io.BytesIO(audio_content), format=\"mp3\")\n",
    "        combined_audio += segment\n",
    "\n",
    "    combined_audio.export(output_path, format=\"mp3\")\n",
    "    print(f\"Audio file has been saved as {output_path}\")\n",
    "\n",
    "def generate_podcast_from_content(client, content, podcast_title, model, voice_a, voice_b):\n",
    "    \"\"\"Generate a complete podcast audio based on the conversation content.\"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = \"/Users/ycyang/code/test/data/audio/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    audio_path = os.path.join(output_dir, f\"{podcast_title}.mp3\")\n",
    "\n",
    "    audio_files = []\n",
    "\n",
    "    for i, conversation in enumerate(content):\n",
    "        # Generate speech for each speaker\n",
    "        for speaker, text in conversation.items():\n",
    "            print(f\"Generating speech for segment {i+1} by speaker {speaker}\")\n",
    "            try:\n",
    "                # Generate speech for different speakers using different voices\n",
    "                voice = voice_a if speaker == 'A' else voice_b\n",
    "                audio_content = generate_speech_chunk(client, model, text, voice)\n",
    "                audio_files.append(audio_content)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to generate speech for segment {i+1} by speaker {speaker}: {e}\")\n",
    "\n",
    "    # Merge audio segments\n",
    "    merge_audio_files(audio_files, audio_path)\n",
    "\n",
    "\n",
    "model = 'tts-1'\n",
    "voice_a = 'nova'  # The host's voice\n",
    "voice_b = 'onyx'  # The interviewee's voice\n",
    "\n",
    "generate_podcast_from_content(client, content, \"Tech Sharing Podcast\", model, voice_a, voice_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b14248c-2f51-4654-9ffc-b8ac43d5b7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
